// This file is *not* autogenerated, because the entire table is Very Special
// and little-endian.

use bytemuck::AnyBitPattern;

#[allow(unused_imports)]
use crate::codegen_prelude::*;

/// [hvgl](https://developer.apple.com/fonts/TrueType-Reference-Manual/RM06/Chap6hvgl.html) table
#[derive(Debug, Clone, Copy)]
#[doc(hidden)]
pub struct HvglMarker {}

impl HvglMarker {
    pub fn version_byte_range(&self) -> Range<usize> {
        let start = 0;
        start..start + MajorMinor::RAW_BYTE_LEN
    }

    pub fn format_flags_byte_range(&self) -> Range<usize> {
        let start = self.version_byte_range().end;
        start..start + u32::RAW_BYTE_LEN
    }

    pub fn num_parts_byte_range(&self) -> Range<usize> {
        let start = self.format_flags_byte_range().end;
        start..start + u32::RAW_BYTE_LEN
    }

    pub fn part_index_offset_byte_range(&self) -> Range<usize> {
        let start = self.num_parts_byte_range().end;
        start..start + u32::RAW_BYTE_LEN
    }

    pub fn num_glyphs_byte_range(&self) -> Range<usize> {
        let start = self.part_index_offset_byte_range().end;
        start..start + u32::RAW_BYTE_LEN
    }

    pub fn reserved1_byte_range(&self) -> Range<usize> {
        let start = self.num_glyphs_byte_range().end;
        start..start + u32::RAW_BYTE_LEN
    }
}

impl MinByteRange for HvglMarker {
    fn min_byte_range(&self) -> Range<usize> {
        0..self.reserved1_byte_range().end
    }
}

impl TopLevelTable for Hvgl<'_> {
    /// `Hvgl`
    const TAG: Tag = Tag::new(b"hvgl");
}

impl<'a> FontRead<'a> for Hvgl<'a> {
    fn read(data: FontData<'a>) -> Result<Self, ReadError> {
        let mut cursor = data.cursor();
        cursor.advance::<MajorMinor>();
        cursor.advance::<u32>();
        cursor.advance::<u32>();
        cursor.advance::<u32>();
        cursor.advance::<u32>();
        cursor.advance::<u32>();
        cursor.finish(HvglMarker {})
    }
}

/// [hvgl](https://developer.apple.com/fonts/TrueType-Reference-Manual/RM06/Chap6hvgl.html) table
pub type Hvgl<'a> = TableRef<'a, HvglMarker>;

#[allow(clippy::needless_lifetimes)]
impl<'a> Hvgl<'a> {
    /// The major/minor version (3, 1)
    pub fn version(&self) -> MajorMinor {
        let range = self.shape.version_byte_range();
        let [maj1, maj2, min1, min2] = self.data.read_raw_at(range.start).unwrap();
        MajorMinor::new(u16::from_le_bytes([maj1, maj2]), u16::from_le_bytes([min1, min2]))
    }

    /// The number of parts (shapes and composite shapes) in the table
    pub fn num_parts(&self) -> u32 {
        let range = self.shape.num_parts_byte_range();
        u32::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    /// The offset from the beginning of the table to the part index. Currently always 24 (0x18).
    pub fn part_index_offset(&self) -> Offset32 {
        let range = self.shape.part_index_offset_byte_range();
        Offset32::new(u32::from_le_bytes(self.data.read_raw_at(range.start).unwrap()))
    }

    /// The number of externally-visible parts.
    pub fn num_glyphs(&self) -> u32 {
        let range = self.shape.num_glyphs_byte_range();
        u32::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn part_index(&self) -> Result<PartIndex<'a>, ReadError> {
        let data = self.data;
        let args = self.num_parts();
        self.part_index_offset()
            .resolve_with_args(data, &args)
    }
}

#[cfg(feature = "experimental_traverse")]
impl<'a> SomeTable<'a> for Hvgl<'a> {
    fn type_name(&self) -> &str {
        "Hvgl"
    }
    fn get_field(&self, idx: usize) -> Option<Field<'a>> {
        match idx {
            0 => Some(Field::new("version", self.version())),
            1 => Some(Field::new("num_parts", self.num_parts())),
            2 => Some(Field::new("part_index_offset", self.part_index_offset())),
            3 => Some(Field::new(
                "part_index_offset",
                FieldType::offset(
                    self.part_index_offset(),
                    self.part_index(),
                ),
            )),
            4 => Some(Field::new("num_glyphs", self.num_glyphs())),
            _ => None,
        }
    }
}

#[cfg(feature = "experimental_traverse")]
#[allow(clippy::needless_lifetimes)]
impl<'a> std::fmt::Debug for Hvgl<'a> {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        (self as &dyn SomeTable<'a>).fmt(f)
    }
}

/// An array of [Part] tables.
#[derive(Debug, Clone, Copy)]
#[doc(hidden)]
pub struct PartIndexMarker {
    part_offsets_byte_len: usize,
}

impl PartIndexMarker {
    pub fn part_offsets_byte_range(&self) -> Range<usize> {
        0..self.part_offsets_byte_len
    }
}

impl MinByteRange for PartIndexMarker {
    fn min_byte_range(&self) -> Range<usize> {
        0..self.part_offsets_byte_range().end
    }
}

pub type PartIndex<'a> = TableRef<'a, PartIndexMarker>;

impl ReadArgs for PartIndex<'_> {
    type Args = u32;
}

impl<'a> FontReadWithArgs<'a> for PartIndex<'a> {
    fn read_with_args(data: FontData<'a>, args: &u32) -> Result<Self, ReadError> {
        let num_parts = *args;
        let mut cursor = data.cursor();
        let part_offsets_byte_len = (num_parts as usize)
            .checked_mul(Offset32::RAW_BYTE_LEN)
            .ok_or(ReadError::OutOfBounds)?;
        cursor.advance_by(part_offsets_byte_len);
        cursor.advance::<u32>(); // sentinel value at the end of the array
        cursor.finish(PartIndexMarker {
            part_offsets_byte_len,
        })
    }
}

impl<'a> PartIndex<'a> {
    /// A constructor that requires additional arguments.
    ///
    /// This type requires some external state in order to be
    /// parsed.
    pub fn read(data: FontData<'a>, num_parts: u32) -> Result<Self, ReadError> {
        let args = num_parts;
        Self::read_with_args(data, &args)
    }

    pub fn part_offsets(&self) -> &'a [LittleEndian<Offset32>] {
        let range = self.shape.part_offsets_byte_range();
        self.data.read_array(range).unwrap()
    }

    pub fn parts(&self) -> PartArray<'a> {
        let data = self.data;
        let offsets = self.part_offsets();
        PartArray::new(offsets, data)
    }

    pub fn parts_size(&self) -> u32 {
        // The sentinel value at the end of the parts index "points at the end
        // of the last part's data". Relative to what, Apple???
        u32::from_le_bytes(self.data.read_raw_at(self.shape.part_offsets_byte_len).unwrap())
    }
}

#[cfg(feature = "experimental_traverse")]
impl<'a> SomeTable<'a> for PartIndex<'a> {
    fn type_name(&self) -> &str {
        "PartIndex"
    }
    fn get_field(&self, idx: usize) -> Option<Field<'a>> {
        match idx {
            0 => Some({
                let data = self.data;
                Field::new(
                    "part_offsets",
                    FieldType::array_of_offsets(
                        better_type_name::<Part>(),
                        self.part_offsets(),
                        move |off| {
                            let target = off.get().resolve::<Part>(data);
                            FieldType::offset(off.get(), target)
                        },
                    ),
                )
            }),
            _ => None,
        }
    }
}

#[cfg(feature = "experimental_traverse")]
#[allow(clippy::needless_lifetimes)]
impl<'a> std::fmt::Debug for PartIndex<'a> {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        (self as &dyn SomeTable<'a>).fmt(f)
    }
}

pub struct PartArray<'a> {
    offsets: &'a [LittleEndian<Offset32>],
    data: FontData<'a>,
}

impl<'a> PartArray<'a> {
    fn new(offsets: &'a [LittleEndian<Offset32>], data: FontData<'a>) -> Self {
        Self { offsets, data }
    }

    // The following functions are reimplemented here from ArrayOfOffsets, which
    // we can't use because all our offsets are little-endian

    /// The number of offsets in the array
    pub fn len(&self) -> usize {
        self.offsets.len()
    }

    /// `true` if the array is empty
    pub fn is_empty(&self) -> bool {
        self.offsets.is_empty()
    }

    /// Resolve the offset at the provided index.
    ///
    /// Note: if the index is invalid this will return the `InvalidCollectionIndex`
    /// error variant instead of `None`.
    #[inline]
    pub fn get(&self, idx: usize) -> Result<Part<'a>, ReadError> {
        self.offsets
            .get(idx)
            .ok_or(ReadError::InvalidCollectionIndex(idx as _))
            .and_then(|o| o.get().resolve_with_args(self.data, &()))
    }

    /// Iterate over all of the offset targets.
    ///
    /// Each offset will be resolved as it is encountered.
    pub fn iter(&self) -> impl Iterator<Item = Result<Part<'a>, ReadError>> + 'a {
        let mut iter = self.offsets.iter();
        let data = self.data;
        std::iter::from_fn(move || {
            iter.next()
                .map(|off| off.get().resolve_with_args(data, &()))
        })
    }
}

#[derive(Clone)]
pub enum Part<'a> {
    Shape(ShapePart<'a>),
    Composite(CompositePart<'a>),
}

impl<'a> Part<'a> {
    ///Return the `FontData` used to resolve offsets for this table.
    pub fn offset_data(&self) -> FontData<'a> {
        match self {
            Self::Shape(item) => item.offset_data(),
            Self::Composite(item) => item.offset_data(),
        }
    }

    /// Format identifier
    pub fn format(&self) -> u16 {
        match self {
            Self::Shape(item) => item.format(),
            Self::Composite(item) => item.format(),
        }
    }

    pub fn num_total_axes(&self) -> u16 {
        match self {
            Part::Shape(item) => item.num_axes(),
            Part::Composite(item) => item.num_total_axes(),
        }
    }

    pub fn num_total_subparts(&self) -> u16 {
        match self {
            Part::Shape(item) => 1,
            Part::Composite(item) => item.num_total_subparts(),
        }
    }
}

impl<'a> FontRead<'a> for Part<'a> {
    fn read(data: FontData<'a>) -> Result<Self, ReadError> {
        let format = u16::from_le_bytes(data.read_raw_at(0usize)?);
        match format {
            ShapePartMarker::FORMAT => Ok(Self::Shape(FontRead::read(data)?)),
            CompositePartMarker::FORMAT => Ok(Self::Composite(FontRead::read(data)?)),
            other => Err(ReadError::InvalidFormat(other.into())),
        }
    }
}

impl MinByteRange for Part<'_> {
    fn min_byte_range(&self) -> Range<usize> {
        match self {
            Self::Shape(item) => item.min_byte_range(),
            Self::Composite(item) => item.min_byte_range(),
        }
    }
}

#[cfg(feature = "experimental_traverse")]
impl<'a> Part<'a> {
    fn dyn_inner<'b>(&'b self) -> &'b dyn SomeTable<'a> {
        match self {
            Self::Shape(table) => table,
            Self::Composite(table) => table,
        }
    }
}

#[cfg(feature = "experimental_traverse")]
impl std::fmt::Debug for Part<'_> {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        self.dyn_inner().fmt(f)
    }
}

#[cfg(feature = "experimental_traverse")]
impl<'a> SomeTable<'a> for Part<'a> {
    fn type_name(&self) -> &str {
        self.dyn_inner().type_name()
    }
    fn get_field(&self, idx: usize) -> Option<Field<'a>> {
        self.dyn_inner().get_field(idx)
    }
}

impl Format<u16> for ShapePartMarker {
    const FORMAT: u16 = 0;
}

#[derive(Debug, Clone, Copy)]
#[doc(hidden)]
pub struct ShapePartMarker {
    path_sizes_byte_len: usize,
    blend_types_byte_len: usize,
    padding_byte_len: usize,
    master_coordinate_vector_byte_len: usize,
    delta_coordinate_matrix_byte_len: usize,
}

impl ShapePartMarker {
    pub fn format_byte_range(&self) -> Range<usize> {
        let start = 0;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn num_axes_byte_range(&self) -> Range<usize> {
        let start = self.format_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn num_paths_byte_range(&self) -> Range<usize> {
        let start = self.num_axes_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn num_segments_byte_range(&self) -> Range<usize> {
        let start = self.num_paths_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn path_sizes_byte_range(&self) -> Range<usize> {
        let start = self.num_segments_byte_range().end;
        start..start + self.path_sizes_byte_len
    }

    pub fn blend_types_byte_range(&self) -> Range<usize> {
        let start = self.path_sizes_byte_range().end;
        start..start + self.blend_types_byte_len
    }

    pub fn padding_byte_range(&self) -> Range<usize> {
        let start = self.blend_types_byte_range().end;
        start..start + self.padding_byte_len
    }

    pub fn master_coordinate_vector_byte_range(&self) -> Range<usize> {
        let start = self.padding_byte_range().end;
        start..start + self.master_coordinate_vector_byte_len
    }

    pub fn delta_coordinate_matrix_byte_range(&self) -> Range<usize> {
        let start = self.master_coordinate_vector_byte_range().end;
        start..start + self.delta_coordinate_matrix_byte_len
    }
}

impl MinByteRange for ShapePartMarker {
    fn min_byte_range(&self) -> Range<usize> {
        0..self.format_byte_range().end
    }
}

impl<'a> FontRead<'a> for ShapePart<'a> {
    fn read(data: FontData<'a>) -> Result<Self, ReadError> {
        let mut cursor = data.cursor();
        cursor.advance::<u16>(); // format flag
        let num_axes = u16::from_le_bytes(cursor.read_raw()?);
        let num_paths = u16::from_le_bytes(cursor.read_raw()?);
        let num_segments = u16::from_le_bytes(cursor.read_raw()?);
        let path_sizes_byte_len = (num_paths as usize).checked_mul(u16::RAW_BYTE_LEN).ok_or(ReadError::OutOfBounds)?;
        cursor.advance_by(path_sizes_byte_len);
        let blend_types_byte_len = (num_segments as usize).checked_mul(CoordBlendType::RAW_BYTE_LEN).ok_or(ReadError::OutOfBounds)?;
        cursor.advance_by(blend_types_byte_len);
        // Mathematically, none of these operations can overflow
        let padding_byte_len = (f64::RAW_BYTE_LEN - (cursor.position()? % f64::RAW_BYTE_LEN)) % f64::RAW_BYTE_LEN;
        cursor.advance_by(padding_byte_len);
        // 4 coordinates per segment
        let master_coordinate_vector_byte_len = (num_segments as usize).checked_mul(f64::RAW_BYTE_LEN * 4).ok_or(ReadError::OutOfBounds)?;
        // matrix with (4 * segments) rows and (2 * axes) columns
        let delta_coordinate_matrix_byte_len = (num_segments as usize).checked_mul(num_axes as usize).and_then(|n| n.checked_mul(4 * 2)).and_then(|n| n.checked_mul(f64::RAW_BYTE_LEN)).ok_or(ReadError::OutOfBounds)?;
        cursor.finish(ShapePartMarker {
            path_sizes_byte_len,
            blend_types_byte_len,
            padding_byte_len,
            master_coordinate_vector_byte_len,
            delta_coordinate_matrix_byte_len,
        })
    }
}

pub type ShapePart<'a> = TableRef<'a, ShapePartMarker>;

#[allow(clippy::needless_lifetimes)]
impl<'a> ShapePart<'a> {
    /// Format identifier — set to 0.
    pub fn format(&self) -> u16 {
        let range = self.shape.format_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn num_axes(&self) -> u16 {
        let range = self.shape.num_axes_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn num_paths(&self) -> u16 {
        let range = self.shape.num_paths_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn num_segments(&self) -> u16 {
        let range = self.shape.num_segments_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn path_sizes(&self) -> &'a [LittleEndian<u16>] {
        let range = self.shape.path_sizes_byte_range();
        self.data.read_array(range).unwrap()
    }

    // TODO: change to LittleEndian if we move that type into font-types and can blanket impl AnyBitPattern
    pub fn blend_types(&self) -> &'a [BigEndian<CoordBlendType>] {
        let range = self.shape.blend_types_byte_range();
        self.data.read_array(range).unwrap()
    }

    pub fn master_coordinate_vector(&self) -> &'a [LittleEndian<f64>] {
        let range = self.shape.master_coordinate_vector_byte_range();
        self.data.read_array(range).unwrap()
    }

    pub fn delta_coordinate_matrix(&self) -> &'a [LittleEndian<f64>] {
        let range = self.shape.delta_coordinate_matrix_byte_range();
        self.data.read_array(range).unwrap()
    }
}

#[cfg(feature = "experimental_traverse")]
impl<'a> SomeTable<'a> for ShapePart<'a> {
    fn type_name(&self) -> &str {
        "ShapePart"
    }
    fn get_field(&self, idx: usize) -> Option<Field<'a>> {
        match idx {
            // TODO
            _ => None,
        }
    }
}

#[cfg(feature = "experimental_traverse")]
#[allow(clippy::needless_lifetimes)]
impl<'a> std::fmt::Debug for ShapePart<'a> {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        (self as &dyn SomeTable<'a>).fmt(f)
    }
}

#[derive(Clone, Debug, PartialEq, Eq, PartialOrd, Ord, Hash, Copy, AnyBitPattern)]
#[repr(C)]
#[repr(packed)]
pub struct SubpartRecord {
    pub part_table_index: LittleEndian<u32>,
    pub tree_part_index: LittleEndian<u16>,
    pub tree_axis_index: LittleEndian<u16>,
}

impl SubpartRecord {
    pub fn part_table_index(&self) -> u32 {
        self.part_table_index.get()
    }

    pub fn tree_part_index(&self) -> u16 {
        self.tree_part_index.get()
    }

    pub fn tree_axis_index(&self) -> u16 {
        self.tree_axis_index.get()
    }
}

impl FixedSize for SubpartRecord {
    const RAW_BYTE_LEN: usize =
        u32::RAW_BYTE_LEN + u16::RAW_BYTE_LEN + u16::RAW_BYTE_LEN;
}

#[cfg(feature = "experimental_traverse")]
impl<'a> SomeRecord<'a> for SubpartRecord {
    fn traverse(self, data: FontData<'a>) -> RecordResolver<'a> {
        RecordResolver {
            name: "SubpartRecord",
            get_field: Box::new(move |idx, _data| match idx {
                // TODO
                _ => None,
            }),
            data,
        }
    }
}

impl Format<u16> for CompositePartMarker {
    const FORMAT: u16 = 1;
}

#[derive(Debug, Clone, Copy)]
#[doc(hidden)]
pub struct CompositePartMarker {
    /*subparts_byte_len: usize,
    extremum_column_starts_byte_len: usize,
    master_row_indices_byte_len: usize,
    extremum_row_indices_byte_len: usize,
    master_axis_value_deltas_byte_len: usize,
    extremum_axis_value_deltas_byte_len: usize,
    master_translation_deltas_byte_len: usize,
    extremum_translation_deltas_byte_len: usize,
    extremum_translation_indices_byte_len: usize,
    master_translation_indices_byte_len: usize,
    master_rotation_deltas_byte_len: usize,
    extremum_rotation_deltas_byte_len: usize,
    extremum_rotation_indices_byte_len: usize,
    master_rotation_indices_byte_len: usize,*/
}

impl CompositePartMarker {
    pub fn format_byte_range(&self) -> Range<usize> {
        let start = 0;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn num_direct_axes_byte_range(&self) -> Range<usize> {
        let start = self.format_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn num_direct_subparts_byte_range(&self) -> Range<usize> {
        let start = self.num_direct_axes_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn num_total_subparts_byte_range(&self) -> Range<usize> {
        let start = self.num_direct_subparts_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn num_total_axes_byte_range(&self) -> Range<usize> {
        let start = self.num_total_subparts_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn max_extremes_byte_range(&self) -> Range<usize> {
        let start = self.num_total_axes_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn num_master_axis_values_byte_range(&self) -> Range<usize> {
        let start = self.max_extremes_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn num_extremum_axis_values_byte_range(&self) -> Range<usize> {
        let start = self.num_master_axis_values_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn num_master_translations_byte_range(&self) -> Range<usize> {
        let start = self.num_extremum_axis_values_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn num_master_rotations_byte_range(&self) -> Range<usize> {
        let start = self.num_master_translations_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn num_extremum_translations_byte_range(&self) -> Range<usize> {
        let start = self.num_master_rotations_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn num_extremum_rotations_byte_range(&self) -> Range<usize> {
        let start = self.num_extremum_translations_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn subpart_array_offset_byte_range(&self) -> Range<usize> {
        let start = self.num_extremum_rotations_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn extremum_column_starts_offset_byte_range(&self) -> Range<usize> {
        let start = self.subpart_array_offset_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn master_axis_deltas_offset_byte_range(&self) -> Range<usize> {
        let start = self.extremum_column_starts_offset_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn extremum_axis_deltas_offset_byte_range(&self) -> Range<usize> {
        let start = self.master_axis_deltas_offset_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn translations_offset_byte_range(&self) -> Range<usize> {
        let start = self.extremum_axis_deltas_offset_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }

    pub fn rotations_offset_byte_range(&self) -> Range<usize> {
        let start = self.translations_offset_byte_range().end;
        start..start + u16::RAW_BYTE_LEN
    }
}

impl MinByteRange for CompositePartMarker {
    fn min_byte_range(&self) -> Range<usize> {
        0..self.format_byte_range().end
    }
}

impl<'a> FontRead<'a> for CompositePart<'a> {
    fn read(data: FontData<'a>) -> Result<Self, ReadError> {
        let mut cursor = data.cursor();
        cursor.advance::<u16>(); // format flag
        let num_direct_axes = u16::from_le_bytes(cursor.read_raw()?);
        let num_direct_subparts = u16::from_le_bytes(cursor.read_raw()?);
        let num_total_subparts = u16::from_le_bytes(cursor.read_raw()?);
        let num_total_axes = u16::from_le_bytes(cursor.read_raw()?);
        let max_extremes = u16::from_le_bytes(cursor.read_raw()?);
        let num_master_axis_values = u16::from_le_bytes(cursor.read_raw()?);
        let num_extremum_axis_values = u16::from_le_bytes(cursor.read_raw()?);
        let num_master_translations = u16::from_le_bytes(cursor.read_raw()?);
        let num_master_rotations = u16::from_le_bytes(cursor.read_raw()?);
        let num_extremum_translations = u16::from_le_bytes(cursor.read_raw()?);
        let num_extremum_rotations = u16::from_le_bytes(cursor.read_raw()?);
        cursor.advance::<u16>(); // offset to subpart array / 4
        cursor.advance::<u16>(); // offset to extremum column starts / 4
        cursor.advance::<u16>(); // offset to master axis deltas / 4
        cursor.advance::<u16>(); // offset to extremum axis deltas / 4
        cursor.advance::<u16>(); // offset to all translations / 4
        cursor.advance::<u16>(); // offset to all rotations / 4
        cursor.finish(CompositePartMarker {})
    }
}

pub type CompositePart<'a> = TableRef<'a, CompositePartMarker>;

#[allow(clippy::needless_lifetimes)]
impl<'a> CompositePart<'a> {
    /// Format identifier — set to 1.
    pub fn format(&self) -> u16 {
        let range = self.shape.format_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn num_direct_axes(&self) -> u16 {
        let range = self.shape.num_direct_axes_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn num_direct_subparts(&self) -> u16 {
        let range = self.shape.num_direct_subparts_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn num_total_subparts(&self) -> u16 {
        let range = self.shape.num_total_subparts_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn num_total_axes(&self) -> u16 {
        let range = self.shape.num_total_axes_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn max_extremes(&self) -> u16 {
        let range = self.shape.max_extremes_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn num_master_axis_values(&self) -> u16 {
        let range = self.shape.num_master_axis_values_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn num_extremum_axis_values(&self) -> u16 {
        let range = self.shape.num_extremum_axis_values_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn num_master_translations(&self) -> u16 {
        let range = self.shape.num_master_translations_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn num_master_rotations(&self) -> u16 {
        let range = self.shape.num_master_rotations_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn num_extremum_translations(&self) -> u16 {
        let range = self.shape.num_extremum_translations_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn num_extremum_rotations(&self) -> u16 {
        let range = self.shape.num_extremum_rotations_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    /// This isn't an [`Offset16`] because it's not a "real" offset--it needs to
    /// be multiplied by 4 to get the actual offset.
    fn subpart_array_offset(&self) -> u16 {
        let range = self.shape.subpart_array_offset_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    /// This isn't an [`Offset16`] because it's not a "real" offset--it needs to
    /// be multiplied by 4 to get the actual offset.
    fn extremum_column_starts_offset(&self) -> u16 {
        let range = self.shape.extremum_column_starts_offset_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    /// This isn't an [`Offset16`] because it's not a "real" offset--it needs to
    /// be multiplied by 4 to get the actual offset.
    fn master_axis_deltas_offset(&self) -> u16 {
        let range = self.shape.master_axis_deltas_offset_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    /// This isn't an [`Offset16`] because it's not a "real" offset--it needs to
    /// be multiplied by 4 to get the actual offset.
    fn extremum_axis_deltas_offset(&self) -> u16 {
        let range = self.shape.extremum_axis_deltas_offset_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    /// This isn't an [`Offset16`] because it's not a "real" offset--it needs to
    /// be multiplied by 4 to get the actual offset.
    fn translations_offset(&self) -> u16 {
        let range = self.shape.translations_offset_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    /// This isn't an [`Offset16`] because it's not a "real" offset--it needs to
    /// be multiplied by 4 to get the actual offset.
    fn rotations_offset(&self) -> u16 {
        let range = self.shape.rotations_offset_byte_range();
        u16::from_le_bytes(self.data.read_raw_at(range.start).unwrap())
    }

    pub fn subparts(&self) -> Result<&[SubpartRecord], ReadError> {
        // This can't overflow but it's good practice to use checked ops anyway
        let offset = (self.subpart_array_offset() as usize).checked_mul(4).ok_or(ReadError::OutOfBounds)?;
        let end = (self.num_direct_subparts() as usize).checked_mul(SubpartRecord::RAW_BYTE_LEN).and_then(|len| offset.checked_add(len)).ok_or(ReadError::OutOfBounds)?;
        self.data.read_array(offset..end)
    }

    fn extremum_column_starts_byte_range(&self) -> Result<Range<usize>, ReadError> {
        // This can't overflow but it's good practice to use checked ops anyway
        let start = (self.extremum_column_starts_offset() as usize).checked_mul(4).ok_or(ReadError::OutOfBounds)?;
        // Array of (2 * axisCount) + 1 u16s. The last one is a sentinel value.
        let end = (self.num_direct_axes() as usize)
            .checked_mul(2)
            .and_then(|n| n.checked_add(1))
            .and_then(|n| n.checked_mul(u16::RAW_BYTE_LEN))
            .and_then(|len| start.checked_add(len)).ok_or(ReadError::OutOfBounds)?;

        Ok(start..end)
    }

    pub fn extremum_column_starts(&self) -> Result<&[LittleEndian<u16>], ReadError> {
        self.data.read_array(self.extremum_column_starts_byte_range()?)
    }

    fn master_row_indices_byte_range(&self) -> Result<Range<usize>, ReadError> {
        // This can't overflow but it's good practice to use checked ops anyway
        let start = self.extremum_column_starts_byte_range()?.end;
        let end = (self.num_master_axis_values() as usize)
            .checked_mul(u16::RAW_BYTE_LEN)
            .and_then(|len| start.checked_add(len)).ok_or(ReadError::OutOfBounds)?;

        Ok(start..end)
    }

    pub fn master_row_indices(&self) -> Result<&[LittleEndian<u16>], ReadError> {
        self.data.read_array(self.master_row_indices_byte_range()?)
    }

    fn extremum_row_indices_byte_range(&self) -> Result<Range<usize>, ReadError> {
        // This can't overflow but it's good practice to use checked ops anyway
        let start = self.master_row_indices_byte_range()?.end;
        let end = (self.num_extremum_axis_values() as usize)
            .checked_mul(u16::RAW_BYTE_LEN)
            .and_then(|len| start.checked_add(len)).ok_or(ReadError::OutOfBounds)?;

        Ok(start..end)
    }

    pub fn extremum_row_indices(&self) -> Result<&[LittleEndian<u16>], ReadError> {
        self.data.read_array(self.extremum_row_indices_byte_range()?)
    }

    pub fn master_axis_value_deltas(&self) -> Result<&[LittleEndian<f32>], ReadError> {
        // This can't overflow but it's good practice to use checked ops anyway
        let start = (self.master_axis_deltas_offset() as usize).checked_mul(4).ok_or(ReadError::OutOfBounds)?;
        let end = (self.num_master_axis_values() as usize)
            .checked_mul(f32::RAW_BYTE_LEN)
            .and_then(|len| start.checked_add(len)).ok_or(ReadError::OutOfBounds)?;
        self.data.read_array(start..end)
    }

    pub fn extremum_axis_value_deltas(&self) -> Result<&[LittleEndian<f32>], ReadError> {
        // This can't overflow but it's good practice to use checked ops anyway
        let start = (self.extremum_axis_deltas_offset() as usize).checked_mul(4).ok_or(ReadError::OutOfBounds)?;
        let end = (self.num_extremum_axis_values() as usize)
            .checked_mul(f32::RAW_BYTE_LEN)
            .and_then(|len| start.checked_add(len)).ok_or(ReadError::OutOfBounds)?;
        self.data.read_array(start..end)
    }

    fn master_translation_deltas_byte_range(&self) -> Result<Range<usize>, ReadError> {
        // This can't overflow but it's good practice to use checked ops anyway
        let start = (self.translations_offset() as usize).checked_mul(4).ok_or(ReadError::OutOfBounds)?;
        let end = (self.num_master_translations() as usize)
            .checked_mul(TranslationDelta::RAW_BYTE_LEN)
            .and_then(|len| start.checked_add(len)).ok_or(ReadError::OutOfBounds)?;

        Ok(start..end)
    }

    pub fn master_translation_deltas(&self) -> Result<&[LittleEndian<TranslationDelta>], ReadError> {
        self.data.read_array(self.master_translation_deltas_byte_range()?)
    }

    fn extremum_translation_deltas_byte_range(&self) -> Result<Range<usize>, ReadError> {
        // This can't overflow but it's good practice to use checked ops anyway
        let start = self.master_translation_deltas_byte_range()?.end;
        let end = (self.num_extremum_translations() as usize)
            .checked_mul(TranslationDelta::RAW_BYTE_LEN)
            .and_then(|len| start.checked_add(len)).ok_or(ReadError::OutOfBounds)?;

        Ok(start..end)
    }

    pub fn extremum_translation_deltas(&self) -> Result<&[LittleEndian<TranslationDelta>], ReadError> {
        self.data.read_array(self.extremum_translation_deltas_byte_range()?)
    }

    fn extremum_translation_indices_byte_range(&self) -> Result<Range<usize>, ReadError> {
        // This can't overflow but it's good practice to use checked ops anyway
        let start = self.extremum_translation_deltas_byte_range()?.end;
        let end = (self.num_extremum_translations() as usize)
            .checked_mul(MatrixIndexRecord::RAW_BYTE_LEN)
            .and_then(|len| start.checked_add(len)).ok_or(ReadError::OutOfBounds)?;

        Ok(start..end)
    }

    pub fn extremum_translation_indices(&self) -> Result<&[MatrixIndexRecord], ReadError> {
        self.data.read_array(self.extremum_translation_indices_byte_range()?)
    }

    fn master_translation_indices_byte_range(&self) -> Result<Range<usize>, ReadError> {
        // This can't overflow but it's good practice to use checked ops anyway
        let start = self.extremum_translation_indices_byte_range()?.end;
        let end = (self.num_master_translations() as usize)
            .checked_mul(u16::RAW_BYTE_LEN)
            .and_then(|len| start.checked_add(len)).ok_or(ReadError::OutOfBounds)?;

        Ok(start..end)
    }

    pub fn master_translation_indices(&self) -> Result<&[LittleEndian<u16>], ReadError> {
        self.data.read_array(self.master_translation_indices_byte_range()?)
    }

    fn master_rotation_deltas_byte_range(&self) -> Result<Range<usize>, ReadError> {
        // This can't overflow but it's good practice to use checked ops anyway
        let start = (self.rotations_offset() as usize).checked_mul(4).ok_or(ReadError::OutOfBounds)?;
        let end = (self.num_master_rotations() as usize)
            .checked_mul(f32::RAW_BYTE_LEN)
            .and_then(|len| start.checked_add(len)).ok_or(ReadError::OutOfBounds)?;

        Ok(start..end)
    }

    pub fn master_rotation_deltas(&self) -> Result<&[LittleEndian<f32>], ReadError> {
        self.data.read_array(self.master_rotation_deltas_byte_range()?)
    }

    fn extremum_rotation_deltas_byte_range(&self) -> Result<Range<usize>, ReadError> {
        // This can't overflow but it's good practice to use checked ops anyway
        let start = self.master_rotation_deltas_byte_range()?.end;
        let end = (self.num_extremum_rotations() as usize)
            .checked_mul(f32::RAW_BYTE_LEN)
            .and_then(|len| start.checked_add(len)).ok_or(ReadError::OutOfBounds)?;

        Ok(start..end)
    }

    pub fn extremum_rotation_deltas(&self) -> Result<&[LittleEndian<f32>], ReadError> {
        self.data.read_array(self.extremum_rotation_deltas_byte_range()?)
    }

    fn extremum_rotation_indices_byte_range(&self) -> Result<Range<usize>, ReadError> {
        // This can't overflow but it's good practice to use checked ops anyway
        let start = self.extremum_rotation_deltas_byte_range()?.end;
        let end = (self.num_extremum_rotations() as usize)
            .checked_mul(MatrixIndexRecord::RAW_BYTE_LEN)
            .and_then(|len| start.checked_add(len)).ok_or(ReadError::OutOfBounds)?;

        Ok(start..end)
    }

    pub fn extremum_rotation_indices(&self) -> Result<&[MatrixIndexRecord], ReadError> {
        self.data.read_array(self.extremum_rotation_indices_byte_range()?)
    }

    fn master_rotation_indices_byte_range(&self) -> Result<Range<usize>, ReadError> {
        // This can't overflow but it's good practice to use checked ops anyway
        let start = self.extremum_rotation_indices_byte_range()?.end;
        let end = (self.num_master_rotations() as usize)
            .checked_mul(u16::RAW_BYTE_LEN)
            .and_then(|len| start.checked_add(len)).ok_or(ReadError::OutOfBounds)?;

        Ok(start..end)
    }

    pub fn master_rotation_indices(&self) -> Result<&[LittleEndian<u16>], ReadError> {
        self.data.read_array(self.master_rotation_indices_byte_range()?)
    }

}

#[cfg(feature = "experimental_traverse")]
impl<'a> SomeTable<'a> for CompositePart<'a> {
    fn type_name(&self) -> &str {
        "CompositePart"
    }
    fn get_field(&self, idx: usize) -> Option<Field<'a>> {
        match idx {
            // TODO
            _ => None,
        }
    }
}

#[cfg(feature = "experimental_traverse")]
#[allow(clippy::needless_lifetimes)]
impl<'a> std::fmt::Debug for CompositePart<'a> {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        (self as &dyn SomeTable<'a>).fmt(f)
    }
}

#[derive(Clone, Copy, Debug, Default, AnyBitPattern)]
#[repr(C)]
pub struct TranslationDelta {
    pub x: f32,
    pub y: f32,
}

impl ScalarLE for TranslationDelta {
    type Raw = [u8; std::mem::size_of::<f32>() * 2];

    fn from_raw_le(raw: Self::Raw) -> Self {
        let x = f32::from_le_bytes(raw[0..4].try_into().unwrap());
        let y = f32::from_le_bytes(raw[4..8].try_into().unwrap());
        Self { x, y }
    }

    fn to_raw_le(self) -> Self::Raw {
        let mut dst = [0u8; 8];
        dst[0..4].copy_from_slice(&self.x.to_le_bytes());
        dst[4..8].copy_from_slice(&self.y.to_le_bytes());
        dst
    }
}

impl FixedSize for TranslationDelta {
    const RAW_BYTE_LEN: usize = std::mem::size_of::<<Self as ScalarLE>::Raw>();
}

#[derive(Clone, Debug, PartialEq, Eq, PartialOrd, Ord, Hash, Copy, AnyBitPattern)]
#[repr(C)]
#[repr(packed)]
pub struct MatrixIndexRecord {
    pub row: LittleEndian<u16>,
    pub column: LittleEndian<u16>,
}

impl MatrixIndexRecord {
    pub fn row(&self) -> u16 {
        self.row.get()
    }

    pub fn column(&self) -> u16 {
        self.column.get()
    }
}

impl FixedSize for MatrixIndexRecord {
    const RAW_BYTE_LEN: usize = u16::RAW_BYTE_LEN + u16::RAW_BYTE_LEN;
}

#[cfg(feature = "experimental_traverse")]
impl<'a> SomeRecord<'a> for MatrixIndexRecord {
    fn traverse(self, data: FontData<'a>) -> RecordResolver<'a> {
        RecordResolver {
            name: "MatrixIndexRecord",
            get_field: Box::new(move |idx, _data| match idx {
                // TODO
                _ => None,
            }),
            data,
        }
    }
}

#[derive(Clone, Copy, Debug, Default, PartialEq, Eq, Hash, PartialOrd, Ord)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize))]
#[repr(u8)]
#[allow(clippy::manual_non_exhaustive)]
pub enum CoordBlendType {
    #[default]
    Curve = 0,
    Corner = 1,
    IsolatedTangent = 2,
    FirstTangent = 3,
    SecondTangent = 4,
    #[doc(hidden)]
    /// If font data is malformed we will map unknown values to this variant
    Unknown,
}

impl CoordBlendType {
    /// Create from a raw scalar.
    ///
    /// This will never fail; unknown values will be mapped to the `Unknown` variant
    pub fn new(raw: u8) -> Self {
        match raw {
            0 => Self::Curve,
            1 => Self::Corner,
            2 => Self::IsolatedTangent,
            3 => Self::FirstTangent,
            4 => Self::SecondTangent,
            _ => Self::Unknown,
        }
    }
}

impl font_types::Scalar for CoordBlendType {
    type Raw = <u8 as font_types::Scalar>::Raw;
    fn to_raw(self) -> Self::Raw {
        (self as u8).to_raw()
    }
    fn from_raw(raw: Self::Raw) -> Self {
        let t = <u8>::from_raw(raw);
        Self::new(t)
    }
}

#[cfg(feature = "experimental_traverse")]
impl<'a> From<CoordBlendType> for FieldType<'a> {
    fn from(src: CoordBlendType) -> FieldType<'a> {
        (src as u8).into()
    }
}

// ----------------------------------------------------------------------------

pub trait ByteArray:
    Copy + AsRef<[u8]> + bytemuck::AnyBitPattern + bytemuck::Zeroable
{
    /// Must always succeed for `[u8; N]` if `slice.len() == N`, must fail otherwise
    fn from_slice(slice: &[u8]) -> Option<Self>;
}

impl<const N: usize> ByteArray for [u8; N] {
    fn from_slice(slice: &[u8]) -> Option<Self> {
        slice.try_into().ok()
    }
}

pub trait ScalarLE: Sized {
    /// The raw byte representation of this type.
    type Raw: ByteArray;

    /// Create an instance of this type from raw little-endian bytes
    fn from_raw_le(raw: Self::Raw) -> Self;

    /// Encode this type as raw little-endian bytes
    fn to_raw_le(self) -> Self::Raw;

    /// Attempt to read a ScalarLE from a slice.
    ///
    /// This will always succeed if `slice.len() == Self::RAW_BYTE_LEN`, and will
    /// always return `None` otherwise.
    fn read(slice: &[u8]) -> Option<Self> {
        ByteArray::from_slice(slice).map(Self::from_raw_le)
    }
}

/// A wrapper around raw little-endian bytes for some type.
#[derive(Clone, Copy, PartialEq, Eq, Hash, AnyBitPattern)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize))]
#[repr(transparent)]
pub struct LittleEndian<T: ScalarLE>(pub(crate) T::Raw);

impl<T: ScalarLE> LittleEndian<T> {
    /// construct a new `LittleEndian<T>` from raw bytes
    pub fn new(raw: T::Raw) -> LittleEndian<T> {
        LittleEndian(raw)
    }

    /// Attempt to construct a new raw value from this slice.
    ///
    /// This will fail if `slice.len() != T::RAW_BYTE_LEN`.
    /*pub fn from_slice(slice: &[u8]) -> Option<Self> {
        todo!()
    }*/

    /// Convert this raw type to its native representation.
    #[inline(always)]
    pub fn get(&self) -> T {
        T::from_raw_le(self.0)
    }

    /// Set the value, overwriting the bytes.
    pub fn set(&mut self, value: T) {
        self.0 = value.to_raw_le();
    }

    /// Get the raw little-endian bytes.
    pub fn le_bytes(&self) -> &[u8] {
        self.0.as_ref()
    }
}

impl<T: ScalarLE> From<T> for LittleEndian<T> {
    #[inline]
    fn from(val: T) -> Self {
        LittleEndian(val.to_raw_le())
    }
}

impl<T: ScalarLE + Default> Default for LittleEndian<T> {
    fn default() -> Self {
        Self::from(T::default())
    }
}

//NOTE: do to the orphan rules, we cannot impl the inverse of this, e.g.
// impl<T> PartialEq<LittleEndian<T>> for T (<https://doc.rust-lang.org/error_codes/E0210.html>)
impl<T: ScalarLE + Copy + PartialEq> PartialEq<T> for LittleEndian<T> {
    fn eq(&self, other: &T) -> bool {
        self.get() == *other
    }
}

impl<T: ScalarLE + Copy + PartialOrd + PartialEq> PartialOrd for LittleEndian<T>
where
    <T as ScalarLE>::Raw: PartialEq,
{
    fn partial_cmp(&self, other: &Self) -> Option<core::cmp::Ordering> {
        self.get().partial_cmp(&other.get())
    }
}

impl<T: ScalarLE + Copy + Ord + Eq> Ord for LittleEndian<T>
where
    <T as ScalarLE>::Raw: Eq,
{
    fn cmp(&self, other: &Self) -> core::cmp::Ordering {
        self.get().cmp(&other.get())
    }
}

impl<T: ScalarLE + FixedSize> FixedSize for LittleEndian<T> {
    const RAW_BYTE_LEN: usize = T::RAW_BYTE_LEN;
}

impl<T: std::fmt::Debug + ScalarLE + Copy> std::fmt::Debug for LittleEndian<T> {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        self.get().fmt(f)
    }
}

impl<T: std::fmt::Display + ScalarLE + Copy> std::fmt::Display for LittleEndian<T> {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        self.get().fmt(f)
    }
}

impl ScalarLE for u16 {
    type Raw = [u8; 2];

    fn from_raw_le(raw: Self::Raw) -> Self {
        Self::from_le_bytes(raw)
    }

    fn to_raw_le(self) -> Self::Raw {
        self.to_le_bytes()
    }
}

impl ScalarLE for u32 {
    type Raw = [u8; 4];

    fn from_raw_le(raw: Self::Raw) -> Self {
        Self::from_le_bytes(raw)
    }

    fn to_raw_le(self) -> Self::Raw {
        self.to_le_bytes()
    }
}

impl ScalarLE for Offset16 {
    type Raw = <u16 as ScalarLE>::Raw;

    fn from_raw_le(raw: Self::Raw) -> Self {
        Self::new(u16::from_raw_le(raw))
    }

    fn to_raw_le(self) -> Self::Raw {
        (self.to_u32() as u16).to_raw_le()
    }
}

impl ScalarLE for Offset32 {
    type Raw = <u32 as ScalarLE>::Raw;

    fn from_raw_le(raw: Self::Raw) -> Self {
        Self::new(u32::from_raw_le(raw))
    }

    fn to_raw_le(self) -> Self::Raw {
        self.to_u32().to_raw_le()
    }
}

impl ScalarLE for f32 {
    type Raw = [u8; 4];

    fn from_raw_le(raw: Self::Raw) -> Self {
        Self::from_le_bytes(raw)
    }

    fn to_raw_le(self) -> Self::Raw {
        self.to_le_bytes()
    }
}

impl ScalarLE for f64 {
    type Raw = [u8; 8];

    fn from_raw_le(raw: Self::Raw) -> Self {
        Self::from_le_bytes(raw)
    }

    fn to_raw_le(self) -> Self::Raw {
        self.to_le_bytes()
    }
}
